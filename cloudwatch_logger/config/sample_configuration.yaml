# name of the log group to use. If it doesn't exist, will try to create it first
# default value is: ros_log_group
log_group_name: robot_application_name

# name of the log stream to send logs to. If it doesn't exist, will try to create it first
# default value is: ros_log_stream
log_stream_name: device_name

# the frequency to send a batch of logs to CloudWatch Logs in the log group and log stream specified
# e.g. publish a batch of logs every 6 seconds
#      publish_frequency: 6.0
# default value is: 5.0 seconds
publish_frequency: 5.0

# whether to subscribe to the rosout_agg topic to get logs
# default value is: true
sub_to_rosout: true

# other topics to subscribe to get logs
# e.g. subscribe to two topics, one is named topic1, the other is named topic2
#      topics: ['topic1', 'topic2']
# default value is: empty list
topics: []

# list of node names to ignore logs from
# e.g. To ignore all logs from a node named 'Talker' you would use the following configuration:
#      ignore_nodes: ["/Talker"]
ignore_nodes: ["/cloudwatch_logger", "/cloudwatch_metrics_collector"]

# send logs to CloudWatch Logs based on log verbosity level
# allowed values are: DEBUG, INFO, WARN, ERROR, FATAL
# e.g. INFO level logs AND logs of log levels above(WARN, ERROR, FATAL) get sent to CloudWatch Logs
#      min_log_verbosity: INFO
# default value is: DEBUG == logs of all log verbosity levels get sent to CloudWatch Logs
min_log_verbosity: DEBUG

### Options related to uploading to CloudWatch ###

# Maximum number of items to add to the upload queue.
# If this limit is reached the logs will start to be written to disk.
batch_max_queue_size: 1024

# Once this many log items are in the queue a CloudWatch log publish will be triggered.
# If this is not set the logs will be published on a constant timer regardless of the queue size.
# batch_trigger_publish_size: 64

# How many unique logs to send to CloudWatch in each upload
file_upload_batch_size: 50

# Maximum number of files in the upload queue when reading from disk
file_max_queue_size: 2

# Maximum number of files in the upload queue when streaming live logs from the node to CloudWatch logs
stream_max_queue_size: 20

### Options related to offline file management ###
# When this node goes offline or cannot talk to CloudWatch it will store all metrics in text files on disk
# Then when it's back online it will upload them to CloudWatch. These are settings related to this feature.

# This prefix will be added to all offline log files
file_prefix: "cwlog"

# This file extension will be used for all offline log files
file_extension: ".log"

# The maximum size of each file in offline storage in KB
maximum_file_size: 1024

# The absolute path to a folder that all offline logs will be stored in
storage_directory: "~/.ros/cwlogs/"

# The maximum size of all files in offline storage in KB
storage_limit: 1048576

# This is the AWS Client Configuration used by the AWS service client in the Node. If given the node will load the
# provided configuration when initializing the client.
aws_client_configuration:
  # in an aws account, you can switch to a different region using the drop-down on the upper right corner
  # logs sent to CloudWatch Logs will appear in the region indicated below
  # default value is: "us-west-2"
  region: "us-west-2"

  # Values that determine the length of time, in milliseconds, to wait before timing out a request. You can increase
  # this value if you need to transfer large files, such as in Amazon S3 or Amazon CloudFront.
  connect_timeout_ms: 2000
  request_timeout_ms: 2000

  # The retry strategy used when connection requests are attempted. If set to true then requests
  # will fail fast, otherwise will use an exponential retry algorithm defined by the AWS SDK.
  no_retry_strategy: true
